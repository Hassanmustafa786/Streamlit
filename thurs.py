import streamlit as st
import os
import time
from deep_translator import GoogleTranslator
from audio_recorder_streamlit import audio_recorder
from textblob import TextBlob
import uuid
import io
import pyttsx3
from gtts import gTTS
import speech_recognition as sr
from openai import OpenAI
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from operator import itemgetter
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda, RunnablePassthrough


def recognize_audio(audio_bytes, lang):
    query = ""  
    if audio_bytes:
        # st.audio(audio_bytes, format="audio/wav")
        r = sr.Recognizer()
        try:
            with io.BytesIO(audio_bytes) as wav_io:
                with sr.AudioFile(wav_io) as source:
                    audio_data = r.record(source)
                    query = r.recognize_google(audio_data, language= lang)  # Change the language code if needed
                    st.warning(f"You: {query}\n")
        except sr.UnknownValueError:
            st.error("Google Speech Recognition could not understand audio.")
        except sr.RequestError as e:
            st.error(f"Could not request results from Google Speech Recognition service; {e}")
    
    return query

os.makedirs('Questions/English', exist_ok=True)
os.makedirs('Questions/Urdu', exist_ok=True)
os.makedirs('Questions/Spanish', exist_ok=True)
os.makedirs('Questions/Bengali', exist_ok=True)
os.makedirs('Questions/Arabic', exist_ok=True)

os.makedirs('Answers/English', exist_ok=True)
os.makedirs('Answers/Urdu', exist_ok=True)
os.makedirs('Answers/Spanish', exist_ok=True)
os.makedirs('Answers/Bengali', exist_ok=True)
os.makedirs('Answers/Arabic', exist_ok=True)


def speak(question, key, lang):
    if lang == 'en':
        folder_name = 'Questions/English'
    elif lang == 'es':
        folder_name = 'Questions/Spanish'
    elif lang == 'ur': 
        folder_name = 'Questions/Urdu'
    elif lang == 'bn': 
        folder_name = 'Questions/Bengali'
    elif lang == 'ar': 
        folder_name = 'Questions/Arabic'
    
    filename = f'{folder_name}/Q{key}.mp3'
    if not os.path.exists(filename):
        speech = gTTS(text=question, lang=lang, slow=False, tld="co.in")
        speech.save(filename)
    st.audio(filename)

def text_to_speech(answer, key, lang):
    speech = gTTS(text=answer, lang=lang, slow=False, tld="co.in")
    if lang == 'en':
        filename = f'Answers/English/A{key}.mp3'
        speech.save(filename)
    elif lang == 'ur':
        filename = f'Answers/Urdu/A{key}.mp3'
        speech.save(filename)
    elif lang == 'es':
        filename = f'Answers/Spanish/A{key}.mp3'
        speech.save(filename)
    elif lang == 'bn':
        filename = f'Answers/Bengali/A{key}.mp3'
        speech.save(filename)
    elif lang == 'ar':
        filename = f'Answers/Arabic/A{key}.mp3'
        speech.save(filename)
    st.audio(filename)

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
chat = ChatOpenAI(
    temperature=0.5,
    model_name="gpt-3.5-turbo",
    openai_api_key=openai_api_key,
    max_tokens=100,
)

# Create a single memory instance for the entire conversation
memory = ConversationBufferMemory(return_messages=True)

def get_response(input_message, model, memory):
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ You are a Health Care Expert for ICNA Relief, here to guide and assist people with their health questions and concerns. Please provide accurate and helpful information, and always maintain a polite and professional tone.
                       Your answer should be complete and precise.
                       If a user tell his/her name, age, address then just thank him and end the chat.
                       If a user tell his/her about personal life then just thank him and end the chat.
                       You have to answer briefly only health related questions.
                       You understand only these languages urdu, english, spanish, arabic and bengali.
                       If a user talk with different language which is not given then tell him I cannot understand your language."""),
        MessagesPlaceholder(variable_name="history"),
        ("human", f"{input_message}"),
    ])

    chain = (
        RunnablePassthrough.assign(
            history=RunnableLambda(memory.load_memory_variables) | itemgetter("history")
        )
        | prompt
        | model
    )

    inputs = {"input": input_message}
    response = chain.invoke(inputs)

    # Save the context for future interactions
    memory.save_context(inputs, {"output": response.content})
    memory.load_memory_variables({})

    return response.content

questions = [
    ("What is your name?", 1, "Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÙŠØ§ ÛÛ’?", "Â¿CÃ³mo te llamas?", "à¦†à¦ªà¦¨à¦¾à¦° à¦¨à¦¾à¦® à¦•à¦¿?", "Ù…Ø§ Ø§Ø³Ù…ÙƒØŸ"),
    ("What is your age?", 2, "Ø¢Ù¾ Ú©ÛŒ Ø¹Ù…Ø± Ú©ÛŒØ§ ÛÛ’ØŸ", "Â¿CuÃ¡ntos aÃ±os tienes?", "à¦†à¦ªà¦¨à¦¾à¦° à¦¬à¦¯à¦¼à¦¸ à¦•à¦¤?", "Ù…Ø§ Ù‡Ùˆ Ø¹Ù…Ø±ÙƒØŸ"),
    ("What is your address?", 3, "Ø¢Ù¾ Ú©Ø§ Ù¾ØªÛ Ú©ÛŒØ§ ÛÛ’ØŸ", "Â¿CuÃ¡l es su direcciÃ³n?", "à¦†à¦ªà¦¨à¦¾à¦° à¦ à¦¿à¦•à¦¾à¦¨à¦¾ à¦•à¦¿?", "Ù…Ø§ Ù‡Ùˆ Ø¹Ù†ÙˆØ§Ù†ÙƒØŸ"),
    ("Are you taking any Medications? If yes, then please tell name of the medication.", 4, "Ú©ÛŒØ§ Ø¢Ù¾ Ú©ÙˆØ¦ÛŒ Ø¯ÙˆØ§ Ù„Û’ Ø±ÛÛ’ ÛÛŒÚºØŸØ§Ú¯Ø± ÛØ§Úº. Ù¾Ú¾Ø± Ø¯ÙˆØ§ Ú©Ø§ Ù†Ø§Ù… Ø¨ØªØ§Ø¦ÛŒÚº ", "Â¿EstÃ¡ tomando algÃºn medicamento? En caso afirmativo, indique el nombre del medicamento.", "à¦†à¦ªà¦¨à¦¿ à¦•à¦¿ à¦•à§‹à¦¨à§‹ à¦“à¦·à§à¦§ à¦–à¦¾à¦šà§à¦›à§‡à¦¨? à¦¯à¦¦à¦¿ à¦¹à§à¦¯à¦¾à¦, à¦¤à¦¾à¦¹à¦²à§‡ à¦“à¦·à§à¦§à§‡à¦° à¦¨à¦¾à¦® à¦¬à¦²à§à¦¨à¥¤", "Ù‡Ù„ Ø£Ù†Øª Ù…Ø¹ Ø£ÙŠ Ø£Ø¯ÙˆÙŠØ©ØŸ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ù†Ø¹Ù…ØŒ ÙŠØ±Ø¬Ù‰ Ø°ÙƒØ± Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡."),
    ("Can you name the medicines?", 5, "Ú©ÛŒØ§ Ø¢Ù¾ Ø§Ø¯ÙˆÛŒØ§Øª Ú©Û’ Ù†Ø§Ù… Ø¨ØªØ§ Ø³Ú©ØªÛ’ ÛÛŒÚºØŸ ", "Â¿Puedes nombrar los medicamentos?", "à¦“à¦·à§à¦§à§‡à¦° à¦¨à¦¾à¦® à¦¬à¦²à¦¤à§‡ à¦ªà¦¾à¦°à¦¬à§‡à¦¨?", "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŸ"),
    ("What other medicine have you taken in the past?", 6, "Ø¢Ù¾ Ù†Û’ Ù…Ø§Ø¶ÛŒ Ù…ÛŒÚº Ø§ÙˆØ± Ú©ÙˆÙ† Ø³ÛŒ Ø¯ÙˆØ§ Ù„ÛŒ ÛÛ’ØŸ ", "Â¿QuÃ© otro medicamento ha tomado en el pasado?", "à¦…à¦¤à§€à¦¤à§‡ à¦†à¦ªà¦¨à¦¿ à¦…à¦¨à§à¦¯ à¦•à§‹à¦¨ à¦“à¦·à§à¦§ à¦–à§‡à¦¯à¦¼à§‡à¦›à§‡à¦¨?", "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ø£Ø®Ø±Ù‰ Ø§Ù„ØªÙŠ ØªÙ†Ø§ÙˆÙ„ØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø§Ø¶ÙŠØŸ"),
    ("What is your major complaint?", 7, "Ø¢Ù¾ Ú©ÛŒ Ø³Ø¨ Ø³Û’ Ø¨Ú‘ÛŒ Ø´Ú©Ø§ÛŒØª Ú©ÛŒØ§ ÛÛ’ØŸ ", "Â¿CuÃ¡l es su principal queja?", "à¦†à¦ªà¦¨à¦¾à¦° à¦ªà§à¦°à¦§à¦¾à¦¨ à¦…à¦­à¦¿à¦¯à§‹à¦— à¦•à¦¿?", "Ù…Ø§ Ù‡ÙŠ Ø´ÙƒÙˆØ§Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©ØŸ"),
    ("Have you previously suffered from this complaint?", 8, "Ú©ÛŒØ§ Ø¢Ù¾ Ú©Ùˆ Ù¾ÛÙ„Û’ Ø¨Ú¾ÛŒ Ø§Ø³ Ø´Ú©Ø§ÛŒØª Ú©Ø§ Ø³Ø§Ù…Ù†Ø§ Ú©Ø±Ù†Ø§ Ù¾Ú‘Ø§ ÛÛ’ØŸ", "Â¿Ha sufrido anteriormente esta dolencia?", "à¦†à¦ªà¦¨à¦¿ à¦•à¦¿ à¦†à¦—à§‡ à¦à¦‡ à¦…à¦­à¦¿à¦¯à§‹à¦— à¦¥à§‡à¦•à§‡ à¦­à§à¦—à¦›à§‡à¦¨?", "Ù‡Ù„ Ø¹Ø§Ù†ÙŠØª Ù…Ù† Ù‚Ø¨Ù„ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø´ÙƒÙˆÙ‰ØŸ"),
    ("What previous therapists have you seen?", 9, "Ø¢Ù¾ Ù†Û’ Ù¾Ú†Ú¾Ù„Û’ Ú©ÙˆÙ† Ø³Û’ ØªÚ¾Ø±Ø§Ù¾Ø³Ù¹ Ú©Ùˆ Ø¯ÛŒÚ©Ú¾Ø§ ÛÛ’ØŸ", "Â¿A quÃ© terapeuta has visto anteriormente?", "à¦†à¦ªà¦¨à¦¿ à¦•à¦¿ à¦†à¦—à§‡à¦° à¦¥à§‡à¦°à¦¾à¦ªà¦¿à¦¸à§à¦Ÿ à¦¦à§‡à¦–à§‡à¦›à§‡à¦¨?", "Ù…Ø§ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ÙŠÙ† Ø§Ù„Ø³Ø§Ø¨Ù‚ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† Ø±Ø£ÙŠØªÙ‡Ù…ØŸ"),
    ("Can you describe the treatment?", 10, "Ú©ÛŒØ§ Ø¢Ù¾ Ø¹Ù„Ø§Ø¬ Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºØŸ", "Â¿Puede describir el tratamiento?", "à¦†à¦ªà¦¨à¦¿ à¦šà¦¿à¦•à¦¿à¦¤à§à¦¸à¦¾ à¦¬à¦°à§à¦£à¦¨à¦¾ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨?", "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ÙˆØµÙ Ø§Ù„Ø¹Ù„Ø§Ø¬ØŸ"),
    ("What is your family history?", 11, "Ú©ÛŒØ§ Ø¢Ù¾ Ù…Ø¬Ú¾Û’ Ø§Ù¾Ù†Û’ Ø®Ø§Ù†Ø¯Ø§Ù† Ú©ÛŒ ØªØ§Ø±ÛŒØ® Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº Ø¨ØªØ§ Ø³Ú©ØªÛ’ ÛÛŒÚºØŸ", "Â¿CuÃ¡l es su historia familiar?", "à¦†à¦ªà¦¨à¦¾à¦° à¦ªà¦¾à¦°à¦¿à¦¬à¦¾à¦°à¦¿à¦• à¦‡à¦¤à¦¿à¦¹à¦¾à¦¸ à¦•à¦¿?", "Ù…Ø§ Ù‡Ùˆ ØªØ§Ø±ÙŠØ® Ø¹Ø§Ø¦Ù„ØªÙƒØŸ"),
    ("Are you adopted?", 12, "Ú©ÛŒØ§ Ø¢Ù¾ Ú©Ùˆ Ú¯ÙˆØ¯ Ù„ÛŒØ§ Ú¯ÛŒØ§ ØªÚ¾Ø§ØŸ", "Â¿Eres adoptado?", "à¦†à¦ªà¦¨à¦¿ à¦•à¦¿ à¦¦à¦¤à§à¦¤à¦•?", "Ù‡Ù„ Ø£Ù†Øª Ù…ØªØ¨Ù†Ù‰ØŸ"),
    ("If yes, at what age were you adopted?", 13, "Ø§Ú¯Ø± ÛØ§ÚºØŒ ØªÙˆ Ø¢Ù¾ Ú©Ùˆ Ú©Ø³ Ø¹Ù…Ø± Ù…ÛŒÚº Ú¯ÙˆØ¯ Ù„ÛŒØ§ Ú¯ÛŒØ§ ØªÚ¾Ø§ØŸ", "En caso afirmativo, Â¿a quÃ© edad fue adoptado?", "à¦¯à¦¦à¦¿ à¦¹à§à¦¯à¦¾à¦, à¦•à§‹à¦¨ à¦¬à¦¯à¦¼à¦¸à§‡ à¦†à¦ªà¦¨à¦¾à¦•à§‡ à¦¦à¦¤à§à¦¤à¦• à¦¨à§‡à¦“à¦¯à¦¼à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à¦¿à¦²?", "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ù†Ø¹Ù…ØŒ ÙÙŠ Ø£ÙŠ Ø¹Ù…Ø± ØªÙ… ØªØ¨Ù†ÙŠÙƒØŸ"),
    ("How is your relationship with your mother?", 14, "Ù…Ø§Úº Ú©Û’ Ø³Ø§ØªÚ¾ Ø¢Ù¾ Ú©Ø§ Ø±Ø´ØªÛ Ú©ÛŒØ³Ø§ ÛÛ’ØŸ", "Â¿CÃ³mo es tu relaciÃ³n con tu madre?", "à¦†à¦ªà¦¨à¦¾à¦° à¦®à¦¾à¦¯à¦¼à§‡à¦° à¦¸à¦¾à¦¥à§‡ à¦†à¦ªà¦¨à¦¾à¦° à¦¸à¦®à§à¦ªà¦°à§à¦• à¦•à§‡à¦®à¦¨?", "ÙƒÙŠÙ Ù‡ÙŠ Ø¹Ù„Ø§Ù‚ØªÙƒ Ù…Ø¹ ÙˆØ§Ù„Ø¯ØªÙƒØŸ"),
    ("Where did you grow up?", 15, "Ø¢Ù¾ Ú©ÛØ§Úº Ø¨Ú‘Û’ ÛÙˆØ¦Û’ØŸ", "Â¿DÃ³nde creciste?", "à¦†à¦ªà¦¨à¦¿ à¦•à§‹à¦¥à¦¾à¦¯à¦¼ à¦¬à¦¡à¦¼ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¦¨?", "Ø£ÙŠÙ† Ù†Ø´Ø£ØªØŸ"),
    ("Are you married?", 16, "Ú©ÙŠØ§ Ø¢Ù¾ Ø´Ø§Ø¯ÛŒ Ø´Ø¯Û ÛÙŠÚº", "Â¿EstÃ¡s casado?", "à¦†à¦ªà¦¨à¦¿ à¦•à¦¿ à¦¬à¦¿à¦¬à¦¾à¦¹à¦¿à¦¤?", "Ù‡Ù„ Ø£Ù†Øª Ù…ØªØ²ÙˆØ¬ØŸ"),
    ("If yes, specify the date of marriage?", 17, "Ø§Ú¯Ø± ÛØ§ÚºØŒ ØªÙˆ Ø´Ø§Ø¯ÛŒ Ú©ÛŒ ØªØ§Ø±ÛŒØ® Ø¨ØªØ§Ø¦ÛŒÚºØŸ", "En caso afirmativo, especifique la fecha del matrimonio.", "à¦¯à¦¦à¦¿ à¦¹à§à¦¯à¦¾à¦, à¦¬à¦¿à¦¯à¦¼à§‡à¦° à¦¤à¦¾à¦°à¦¿à¦– à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¬à§‡à¦¨?", "Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ù†Ø¹Ù…ØŒ Ø­Ø¯Ø¯ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø²ÙˆØ§Ø¬ØŸ"),
    ("Do you have children?", 18, "Ú©ÛŒØ§ Ø¢Ù¾ Ú©Û’ Ø¨Ú†Û’ ÛÛŒÚºØŸ", "Â¿Tienes hijos?", "à¦†à¦ªà¦¨à¦¾à¦° à¦•à¦¿ à¦¸à¦¨à§à¦¤à¦¾à¦¨ à¦†à¦›à§‡?", "Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø£Ø·ÙØ§Ù„ØŸ"),
    ("If yes, how is your relationship with your children?", 19, "Ú©ÛŒØ§ Ø¢Ù¾ Ú©Û’ Ø¨Ú†Û’ ÛÛŒÚºØŸ", "En caso afirmativo, Â¿cÃ³mo es su relaciÃ³n con sus hijos?", "à¦¯à¦¦à¦¿ à¦¹à§à¦¯à¦¾à¦, à¦†à¦ªà¦¨à¦¾à¦° à¦¸à¦¨à§à¦¤à¦¾à¦¨à¦¦à§‡à¦° à¦¸à¦¾à¦¥à§‡ à¦†à¦ªà¦¨à¦¾à¦° à¦¸à¦®à§à¦ªà¦°à§à¦• à¦•à§‡à¦®à¦¨?", "Ø¥Ø°Ø§ Ù†Ø¹Ù… ÙƒÙŠÙ Ù‡ÙŠ Ø¹Ù„Ø§Ù‚ØªÙƒ Ù…Ø¹ Ø£Ø·ÙØ§Ù„ÙƒØŸ"),
]

# Initialize the responses using Streamlit's session state
if 'en_responses' not in st.session_state:
    st.session_state.en_responses = {}
if 'ur_responses' not in st.session_state:
    st.session_state.ur_responses = {}
if 'es_responses' not in st.session_state:
    st.session_state.es_responses = {}
if 'bn_responses' not in st.session_state:
    st.session_state.bn_responses = {}
if 'ar_responses' not in st.session_state:
    st.session_state.ar_responses = {}
# ar-SA
# if 'audio_responses' not in st.session_state:
#     st.session_state.audio_responses = {}

st.cache()
# Streamlit app
def ask_question():
    # audio_responses = {}
    for i, (en_question, key, ur_question, es_question, bn_question, ar_question) in enumerate(questions):
        response_key = f"response_{i}"
        st.write(f"Question: {i+1}")
        if selected_language == 'en':
            if response_key not in st.session_state.en_responses:
                st.session_state.en_responses[response_key] = ""
            
            speak(en_question, key, selected_language)
            audio_bytes = audio_recorder(key = str(f"Q{i+1}"))
            user_input = recognize_audio(audio_bytes, "en-EN")
            
            if user_input:
                st.session_state.en_responses[response_key] = user_input
                output = get_response(user_input, chat, memory)
                v = str(f"{i+1}")
                text_to_speech(output, v, 'en')
                st.success(f"{output}")

        elif selected_language == 'ur':
            if response_key not in st.session_state.ur_responses:
                st.session_state.ur_responses[response_key] = ""
            
            speak(ur_question, key, selected_language)
            audio_bytes = audio_recorder(key = str(f"Q{i+1}"))
            user_input = recognize_audio(audio_bytes, "ur-UR")
            if user_input:
                st.session_state.ur_responses[response_key] = user_input
                output = get_response(user_input, chat, memory)
                v = str(f"{i+1}")
                text_to_speech(output, v, 'ur')
                st.success(f"{output}")
        
        elif selected_language == 'es':
            if response_key not in st.session_state.es_responses:
                st.session_state.es_responses[response_key] = ""
            
            speak(es_question, key, selected_language)
            audio_bytes = audio_recorder(key = str(f"Q{i+1}"))
            user_input = recognize_audio(audio_bytes, "es-ES")
            if user_input:
                st.session_state.es_responses[response_key] = user_input
                output = get_response(user_input, chat, memory)
                v = str(f"{i+1}")
                text_to_speech(output, v, 'es')
                st.success(f"{output}")
                
        elif selected_language == 'bn':
            if response_key not in st.session_state.bn_responses:
                st.session_state.bn_responses[response_key] = ""
            
            speak(bn_question, key, selected_language)
            audio_bytes = audio_recorder(key = str(f"Q{i+1}"))
            user_input = recognize_audio(audio_bytes, "bn-BD")
            if user_input:
                st.session_state.bn_responses[response_key] = user_input
                output = get_response(user_input, chat, memory)
                v = str(f"{i+1}")
                text_to_speech(output, v, 'bn')
                st.success(f"{output}")
        elif selected_language == 'ar':
            if response_key not in st.session_state.ar_responses:
                st.session_state.ar_responses[response_key] = ""
            
            speak(ar_question, key, selected_language)
            audio_bytes = audio_recorder(key = str(f"Q{i+1}"))
            user_input = recognize_audio(audio_bytes, "ar-SA")
            if user_input:
                st.session_state.ar_responses[response_key] = user_input
                output = get_response(user_input, chat, memory)
                v = str(f"{i+1}")
                text_to_speech(output, v, 'ar')
                st.success(f"{output}")
        else:
            if selected_language == 'en':
                st.warning("Please select the language first.")
            elif selected_language == 'ur':
                st.warning("Ø¨Ø±Ø§Û Ù…ÛØ±Ø¨Ø§Ù†ÛŒ Ø¯ÙˆØ³Ø±Û’ Ø³ÙˆØ§Ù„ Ú©ÛŒ Ø·Ø±Ù Ø¬Ø§Ø¦ÛŒÚºÛ”")
            elif selected_language == 'es':
                st.warning("Por favor, seleccione el idioma primero.")
            elif selected_language == 'bn':
                st.warning("à¦ªà§à¦°à¦¥à¦®à§‡ à¦­à¦¾à¦·à¦¾ à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨ à¦•à¦°à§à¦¨.")
            elif selected_language == 'ar':
                st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ© Ø£ÙˆÙ„Ø§.")
        
        # audio_responses[response_key] = audio_bytes
        # if response_key not in st.session_state.audio_responses:
        #         st.session_state.audio_responses[response_key] = audio_bytes
        st.divider()
    # return audio_responses

def intro():
    if selected_language == 'en':
        speak("Welcome to ICNA-Relief","0", 'en')
    elif selected_language == 'ur':
        speak("Ø¢Ø¦ÛŒ Ø³ÛŒ Ø§ÛŒÙ† Ø§Û’ Ø±ÛŒÙ„ÛŒÙ Ù…ÛŒÚº Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯. Ø´Ú©Ø±ÛŒÛ", '0', 'ur')
    elif selected_language == 'es':
        speak("Bienvenidos a ICNA-Relief", '0', 'es')
    elif selected_language == 'bn':
        speak("ICNA-à¦°à¦¿à¦²à¦¿à¦«à§‡ à¦¸à§à¦¬à¦¾à¦—à¦¤à¦®", '0', 'bn')
    elif selected_language == 'ar':
        speak("Ù…Ø±Ø­Ø¨Ø§ Ø¨ÙƒÙ… ÙÙŠ Ø¥ØºØ§Ø«Ø© ICNA", '0', 'ar')

st.set_page_config(
    page_title="OSTF App",
    page_icon="ğŸ§Š",
    layout="wide",
)
# st.image('Shine.png')
# st.caption='Copyright 2024 by OSTF. All Rights Reserved.'
st.header('Health Intake Questionnaire', divider='rainbow')
st.markdown('''Welcome To! :blue[I C N A] - :blue[Releif Organization]''')

selected_language = st.selectbox("Select Language", ["en", "ur", "es", "bn", "ar"])
tab1, tab2 = st.tabs(["Q & A", "Stored Data"])
with tab1:
    intro()
    st.divider()
    
    ask_question()

with tab2:
    st.write("### User Stored Data")
    # st.success("Stored Data")
    for i, (question, key, ur_question, es_question, bn_question, ar_question) in enumerate(questions):
        response_key = f"response_{i}"
        if selected_language == 'en':
            if response_key in st.session_state.en_responses:
                st.write(f"Q{i+1} - {question} <br> A{i+1} - {st.session_state.en_responses[response_key]}", unsafe_allow_html=True)
                audio_path = f'Answers/English/A{i+1}.mp3'
                if os.path.exists(audio_path):
                    st.audio(audio_path)
                else:
                    st.warning("Audio file not found.")
        elif selected_language == 'ur':
            if response_key in st.session_state.ur_responses:
                st.write(f"Q{i+1} - {ur_question} <br> A{i+1} - {st.session_state.ur_responses[response_key]}", unsafe_allow_html=True)
                audio_path = f'Answers/Urdu/A{i+1}.mp3'
                if os.path.exists(audio_path):
                    st.audio(audio_path)
                else:
                    st.warning("Audio file not found.")
        elif selected_language == 'es':
            if response_key in st.session_state.es_responses:
                st.write(f"Q{i+1} - {es_question} <br> A{i+1} - {st.session_state.es_responses[response_key]}", unsafe_allow_html=True)
                audio_path = f'Answers/Spanish/A{i+1}.mp3'
                if os.path.exists(audio_path):
                    st.audio(audio_path)
                else:
                    st.warning("Audio file not found.")
        elif selected_language == 'bn':
            if response_key in st.session_state.bn_responses:
                st.write(f"Q{i+1} - {bn_question} <br> A{i+1} - {st.session_state.bn_responses[response_key]}", unsafe_allow_html=True)
                audio_path = f'Answers/Bengali/A{i+1}.mp3'
                if os.path.exists(audio_path):
                    st.audio(audio_path)
                else:
                    st.warning("Audio file not found.")
        elif selected_language == 'ar':
            if response_key in st.session_state.ar_responses:
                st.write(f"Q{i+1} - {ar_question} <br> A{i+1} - {st.session_state.ar_responses[response_key]}", unsafe_allow_html=True)
                audio_path = f'Answers/Arabic/A{i+1}.mp3'
                if os.path.exists(audio_path):
                    st.audio(audio_path)
                else:
                    st.warning("Audio file not found.")
        st.divider()